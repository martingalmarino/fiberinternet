# ü§ñ Sistema de Automatizaci√≥n - Telecom & Home Digital DK

## üìÖ Programaci√≥n de Actualizaciones

### üóìÔ∏è Cronograma Implementado

| Tipo | Frecuencia | Horario | Descripci√≥n |
|------|------------|---------|-------------|
| **Fiber Full Update** | Semanal | Lunes 4:00 AM UTC (6:00 AM Copenhague) | Actualizaci√≥n completa de todos los proveedores de Fiber |
| **Fiber Light Check** | 2x por semana | Mi√©rcoles y Viernes 2:00 PM UTC (4:00 PM Copenhague) | Verificaci√≥n r√°pida de cambios de precios de Fiber |
| **Mobile Full Update** | Mensual | 1¬∫ de cada mes 3:00 AM UTC (5:00 AM Copenhague) | Actualizaci√≥n completa de todos los proveedores de Mobil |
| **TV Full Update** | Mensual | 1¬∫ de cada mes 3:00 AM UTC (5:00 AM Copenhague) | Actualizaci√≥n completa de todos los proveedores de TV |
| **Manual QA** | Mensual | Manual | Revisi√≥n manual de datos clave |

### ‚öôÔ∏è Workflows de GitHub Actions

#### 1. **Weekly Full Update** (`scraper-schedule.yml`)
- **Trigger**: Autom√°tico (cron) + Manual
- **Funciones**:
  - Scraping completo de todos los proveedores
  - Detecci√≥n de cambios en datos
  - Commit autom√°tico solo si hay cambios
  - Deploy autom√°tico a Vercel
  - Notificaciones de estado

#### 2. **Light Check** (`scraper-light-check.yml`)
- **Trigger**: Autom√°tico (cron) + Manual
- **Funciones**:
  - Verificaci√≥n r√°pida de proveedores clave de Fiber
  - Detecci√≥n de cambios de promociones
  - Reporte de estado sin commit autom√°tico

#### 3. **Mobile Monthly Update** (`scraper-mobil-schedule.yml`)
- **Trigger**: Autom√°tico (cron) + Manual
- **Funciones**:
  - Scraping completo de todos los proveedores de Mobil
  - Detecci√≥n de cambios en datos
  - Commit autom√°tico solo si hay cambios
  - Deploy autom√°tico a Vercel
  - Notificaciones de estado

#### 4. **TV Monthly Update** (`scraper-tv-schedule.yml`)
- **Trigger**: Autom√°tico (cron) + Manual
- **Funciones**:
  - Scraping completo de todos los proveedores de TV
  - Detecci√≥n de cambios en datos
  - Commit autom√°tico solo si hay cambios
  - Deploy autom√°tico a Vercel
  - Notificaciones de estado

### üéõÔ∏è Modos de Scraping

El scraper soporta 3 modos diferentes:

#### Fiber Scraper:
```bash
# Modo completo (por defecto)
SCRAPER_TYPE=full python scrape_fiber.py

# Verificaci√≥n ligera
SCRAPER_TYPE=light python scrape_fiber.py

# Modo de prueba
SCRAPER_TYPE=test python scrape_fiber.py
```

#### Mobile Scraper:
```bash
# Modo completo (por defecto)
SCRAPER_TYPE=full python scrape_mobil.py

# Verificaci√≥n ligera
SCRAPER_TYPE=light python scrape_mobil.py

# Modo de prueba
SCRAPER_TYPE=test python scrape_mobil.py
```

#### TV Scraper:
```bash
# Modo completo (por defecto)
SCRAPER_TYPE=full python scrape_tv.py

# Verificaci√≥n ligera
SCRAPER_TYPE=light python scrape_tv.py

# Modo de prueba
SCRAPER_TYPE=test python scrape_tv.py
```

### üöÄ Ejecuci√≥n Manual

#### Desde GitHub Actions Dashboard:
1. Ve a **Actions** en el repositorio
2. Selecciona **"Fiber Internet Scraper - Weekly Update"**
3. Click **"Run workflow"**
4. Configura los par√°metros:
   - **Scraper Type**: `full`, `light`, o `test`
   - **Force Update**: `true` para forzar actualizaci√≥n

#### Desde Terminal (desarrollo local):
```bash
cd scraper

# Scraping completo
python scrape_fiber.py

# Verificaci√≥n ligera
SCRAPER_TYPE=light python scrape_fiber.py

# Modo de prueba
SCRAPER_TYPE=test python scrape_fiber.py
```

### üìä Monitoreo y Logs

#### Logs de GitHub Actions:
- **Ubicaci√≥n**: Repositorio ‚Üí Actions ‚Üí [Workflow Name]
- **Contenido**: 
  - Estado de scraping por proveedor
  - N√∫mero de planes encontrados
  - Errores y warnings
  - Resumen de cambios

#### Logs Locales:
- **Archivo**: `scraper/scraper.log`
- **Rotaci√≥n**: Manual (recomendado limpiar semanalmente)

### üîß Configuraci√≥n de Proveedores

#### Habilitar/Deshabilitar Proveedores:
Edita `scraper/scraper.py`:

```python
PROVIDERS = [
    {
        'name': 'Provider Name',
        'scraper': scrape_provider,
        'enabled': True  # Cambiar a False para deshabilitar
    }
]
```

#### A√±adir Nuevos Proveedores:
1. Crear archivo en `scraper/providers/nuevo_provider.py`
2. Implementar funci√≥n `scrape_nuevo_provider()`
3. A√±adir a la lista `PROVIDERS` en `scraper.py`

### üìà M√©tricas y KPIs

#### M√©tricas Autom√°ticas:
- **Total de proveedores activos**
- **N√∫mero de planes por proveedor**
- **Tasa de √©xito de scraping**
- **Frecuencia de cambios detectados**

#### Dashboard de Estado:
- **Frontend**: Muestra "Data opdateret: [fecha]"
- **GitHub**: Summary autom√°tico en cada workflow
- **Logs**: Historial completo de ejecuciones

### üö® Manejo de Errores

#### Errores Comunes:
1. **Proveedor no disponible**: Se omite y contin√∫a con otros
2. **Cambios en estructura web**: Requiere actualizaci√≥n del scraper
3. **Rate limiting**: Implementar delays entre requests
4. **Certificados SSL**: Manejo autom√°tico de warnings

#### Alertas:
- **GitHub Actions**: Notificaciones autom√°ticas en fallos
- **Logs**: Warnings para proveedores con problemas
- **Frontend**: Mensaje de error si no se pueden cargar datos

### üîÑ Evoluci√≥n del Sistema

#### Fase Actual (MVP):
- ‚úÖ Fiber: 1 actualizaci√≥n semanal completa + 2 verificaciones ligeras por semana
- ‚úÖ Mobil: 1 actualizaci√≥n mensual completa
- ‚úÖ TV: 1 actualizaci√≥n mensual completa
- ‚úÖ 15 proveedores de Fiber activos
- ‚úÖ 15 proveedores de Mobil activos
- ‚úÖ 15 proveedores de TV activos
- ‚úÖ Deploy autom√°tico a Vercel

#### Fase de Crecimiento:
- üìà 2-3 actualizaciones semanales
- üìà Monitoreo en tiempo real de promociones
- üìà Alertas autom√°ticas para cambios significativos
- üìà API endpoints para integraciones

#### Fase Avanzada:
- üöÄ Actualizaciones en tiempo real
- üöÄ Machine learning para detecci√≥n de patrones
- üöÄ Integraci√≥n con sistemas de afiliados
- üöÄ Dashboard administrativo

### üõ†Ô∏è Mantenimiento

#### Tareas Semanales:
- [ ] Revisar logs de scraping
- [ ] Verificar que todos los proveedores respondan
- [ ] Actualizar selectores CSS si es necesario

#### Tareas Mensuales:
- [ ] Revisi√≥n manual de precios y promociones
- [ ] An√°lisis de proveedores con baja tasa de √©xito
- [ ] Optimizaci√≥n de performance del scraper
- [ ] Actualizaci√≥n de dependencias

#### Tareas Trimestrales:
- [ ] Evaluaci√≥n de nuevos proveedores
- [ ] Revisi√≥n de estrategia de scraping
- [ ] An√°lisis de competencia
- [ ] Optimizaci√≥n de costos de infraestructura

---

## üìû Soporte

Para problemas o preguntas sobre el sistema de automatizaci√≥n:
1. Revisar logs en GitHub Actions
2. Verificar estado de proveedores individuales
3. Consultar documentaci√≥n del scraper en `scraper/README.md`
4. Contactar al equipo de desarrollo

**√öltima actualizaci√≥n**: Septiembre 2024
