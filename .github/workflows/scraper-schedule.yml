name: Fiber Internet Scraper - Weekly Update

on:
  schedule:
    # Run every Monday at 4:00 AM UTC (6:00 AM Copenhagen time)
    - cron: '0 4 * * 1'
  workflow_dispatch:  # Manual trigger
    inputs:
      scraper_type:
        description: 'Type of scraping to perform'
        required: true
        default: 'full'
        type: choice
        options:
        - full
        - light
        - test
      force_update:
        description: 'Force update even if no changes detected'
        required: false
        default: false
        type: boolean

jobs:
  scraper:
    runs-on: ubuntu-latest
    name: Scrape Fiber Internet Data
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('scraper/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
            
      - name: Install dependencies
        run: |
          cd scraper
          pip install -r requirements.txt
          playwright install chromium
          
      - name: Run scraper
        run: |
          cd scraper
          python scrape_fiber.py
        env:
          SCRAPER_TYPE: ${{ github.event.inputs.scraper_type || 'full' }}
          FORCE_UPDATE: ${{ github.event.inputs.force_update || 'false' }}
          
      - name: Check for changes
        id: changes
        run: |
          if git diff --quiet data/fiber.json; then
            echo "changes=false" >> $GITHUB_OUTPUT
            echo "No changes detected in fiber.json"
          else
            echo "changes=true" >> $GITHUB_OUTPUT
            echo "Changes detected in fiber.json"
          fi
          
      - name: Commit changes
        if: steps.changes.outputs.changes == 'true' || github.event.inputs.force_update == 'true'
        run: |
          git config --local user.email "action@github.com"
          git config --local user.name "GitHub Action"
          git add data/fiber.json scraper/scraper.log
          git commit -m "Auto-update fiber data - $(date '+%Y-%m-%d %H:%M:%S UTC')
          
          - Scraper type: ${{ github.event.inputs.scraper_type || 'full' }}
          - Providers updated: $(grep -c '"provider"' data/fiber.json)
          - Auto-generated by GitHub Actions"
          
      - name: Push changes
        if: steps.changes.outputs.changes == 'true' || github.event.inputs.force_update == 'true'
        uses: ad-m/github-push-action@master
        with:
          github_token: ${{ secrets.GITHUB_TOKEN }}
          
      - name: Update deployment status
        run: |
          echo "## 📊 Scraping Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Date**: $(date '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "- **Type**: ${{ github.event.inputs.scraper_type || 'full' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Changes**: ${{ steps.changes.outputs.changes }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Providers**: $(grep -c '"provider"' data/fiber.json)" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### 🚀 Auto-deployment" >> $GITHUB_STEP_SUMMARY
          echo "Changes will be automatically deployed to Vercel." >> $GITHUB_STEP_SUMMARY
          
      - name: Notify on failure
        if: failure()
        run: |
          echo "## ❌ Scraping Failed" >> $GITHUB_STEP_SUMMARY
          echo "The weekly fiber internet scraper encountered an error." >> $GITHUB_STEP_SUMMARY
          echo "Please check the logs and fix any issues." >> $GITHUB_STEP_SUMMARY
