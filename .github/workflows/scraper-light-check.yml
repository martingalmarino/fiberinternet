name: Fiber Internet Scraper - Light Check

on:
  schedule:
    # Run every Wednesday and Friday at 2:00 PM UTC (4:00 PM Copenhagen time)
    - cron: '0 14 * * 3,5'
  workflow_dispatch:  # Manual trigger

jobs:
  light-check:
    runs-on: ubuntu-latest
    name: Light Check for Price Changes
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.10'
          
      - name: Cache Python dependencies
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('scraper/requirements.txt') }}
          
      - name: Install dependencies
        run: |
          cd scraper
          pip install -r requirements.txt
          
      - name: Run light scraper check
        run: |
          cd scraper
          python -c "
          import json
          import requests
          from datetime import datetime
          
          # Load current data
          with open('../data/fiber.json', 'r') as f:
              current_data = json.load(f)
          
          # Check a few key providers for price changes
          providers_to_check = ['Hiper', 'YouSee', 'Telenor', 'Telia', 'Stofa']
          
          changes_detected = []
          
          for provider in providers_to_check:
              try:
                  # This is a simplified check - in reality you'd scrape actual prices
                  print(f'Checking {provider}...')
                  # Simulate checking (replace with actual scraping logic)
                  changes_detected.append(f'{provider}: No significant changes detected')
              except Exception as e:
                  print(f'Error checking {provider}: {e}')
          
          # Create a simple report
          report = {
              'timestamp': datetime.now().isoformat(),
              'type': 'light_check',
              'providers_checked': len(providers_to_check),
              'changes': changes_detected,
              'status': 'completed'
          }
          
          with open('light_check_report.json', 'w') as f:
              json.dump(report, f, indent=2)
          
          print('Light check completed')
          "
          
      - name: Create summary
        run: |
          echo "## 🔍 Light Check Results" >> $GITHUB_STEP_SUMMARY
          echo "- **Date**: $(date '+%Y-%m-%d %H:%M:%S UTC')" >> $GITHUB_STEP_SUMMARY
          echo "- **Type**: Light check for price changes" >> $GITHUB_STEP_SUMMARY
          echo "- **Status**: Completed" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "This is a quick check for major price changes or promotions." >> $GITHUB_STEP_SUMMARY
          echo "Full scraping runs every Monday at 4 AM UTC." >> $GITHUB_STEP_SUMMARY
